{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Основное задание\n",
    "Возьмите датасет https://www.kaggle.com/ajayrana/hymenoptera-data/kernels  \n",
    "1.Обучите на нем модели ResNet 18 и VGG 16 с нуля (5-10 эпох)  \n",
    "2.Обучите на нем модели ResNet 18 и VGG 16 с использованием FineTuning (5-10 эпох)  \n",
    "3.Добавьте аугментацию данных к пункту 2  \n",
    "  \n",
    "Сравните качество всех 3 полученных подходов  \n",
    "  \n",
    "# Задание со звездочкой  \n",
    "Примените FineTuning ResNet 18 к FashionMnist. Удалось ли увидеть резкое увеличение качества?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.models as models\n",
    "\n",
    "import torchvision as tv\n",
    "import time\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../dll_hw_4_modern_cnn/hymenoptera_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': tv.transforms.Compose([\n",
    "        tv.transforms.RandomResizedCrop(224),\n",
    "        tv.transforms.RandomHorizontalFlip(),\n",
    "        tv.transforms.ToTensor(),\n",
    "        tv.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': tv.transforms.Compose([\n",
    "        tv.transforms.Resize(256),\n",
    "        tv.transforms.CenterCrop(224),\n",
    "        tv.transforms.ToTensor(),\n",
    "        tv.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: tv.datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision.models as models\n",
    "# resnet18 = models.resnet18()\n",
    "# alexnet = models.alexnet()\n",
    "# vgg16 = models.vgg16()\n",
    "# squeezenet = models.squeezenet1_0()\n",
    "# densenet = models.densenet161()\n",
    "# inception = models.inception_v3()\n",
    "# googlenet = models.googlenet()\n",
    "# shufflenet = models.shufflenet_v2_x1_0()\n",
    "# mobilenet = models.mobilenet_v2()\n",
    "# resnext50_32x4d = models.resnext50_32x4d()\n",
    "# wide_resnet50_2 = models.wide_resnet50_2()\n",
    "# mnasnet = models.mnasnet1_0()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision.models as models\n",
    "# resnet18 = models.resnet18(pretrained=True)\n",
    "# alexnet = models.alexnet(pretrained=True)\n",
    "# squeezenet = models.squeezenet1_0(pretrained=True)\n",
    "# vgg16 = models.vgg16(pretrained=True)\n",
    "# densenet = models.densenet161(pretrained=True)\n",
    "# inception = models.inception_v3(pretrained=True)\n",
    "# googlenet = models.googlenet(pretrained=True)\n",
    "# shufflenet = models.shufflenet_v2_x1_0(pretrained=True)\n",
    "# mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "# resnext50_32x4d = models.resnext50_32x4d(pretrained=True)\n",
    "# wide_resnet50_2 = models.wide_resnet50_2(pretrained=True)\n",
    "# mnasnet = models.mnasnet1_0(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Обучите на нем модели ResNet 18 и VGG 16 с нуля (5-10 эпох)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net, dev):\n",
    "    acc_sum, n = torch.Tensor([0]).to(dev), 0\n",
    "    net.eval()\n",
    "    for X, y in data_iter:\n",
    "        X, y = X.to(dev), y.to(dev)\n",
    "        acc_sum += (net(X).argmax(axis=1) == y).sum()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum.item() / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_iter, test_iter, trainer, num_epochs, dev):\n",
    "    loss = nn.CrossEntropyLoss(reduction='sum')\n",
    "    net.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            trainer.zero_grad()\n",
    "            X, y = X.to(dev), y.to(dev)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "            print(\"Step. time since epoch: {:.3f}. Train acc: {:.3f}. Train Loss: {:.3f}\".format(time.time() -  start,\n",
    "                (y_hat.argmax(axis=1) == y).sum().item() / y.shape[0], l.item()))\n",
    "        test_acc = evaluate_accuracy(test_iter, net, dev)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\n",
    "              'time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc,\n",
    "                 time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 3.731. Train acc: 0.000. Train Loss: 223.353\n",
      "Step. time since epoch: 3.794. Train acc: 0.375. Train Loss: 226.487\n",
      "Step. time since epoch: 3.857. Train acc: 0.594. Train Loss: 141.302\n",
      "Step. time since epoch: 3.921. Train acc: 0.500. Train Loss: 132.527\n",
      "Step. time since epoch: 3.989. Train acc: 0.469. Train Loss: 128.991\n",
      "Step. time since epoch: 4.053. Train acc: 0.562. Train Loss: 65.717\n",
      "Step. time since epoch: 4.119. Train acc: 0.562. Train Loss: 44.617\n",
      "Step. time since epoch: 4.165. Train acc: 0.800. Train Loss: 18.436\n",
      "epoch 1, loss 4.0223, train acc 0.467, test acc 0.458, time 7.0 sec\n",
      "Step. time since epoch: 1.905. Train acc: 0.469. Train Loss: 974.624\n",
      "Step. time since epoch: 2.082. Train acc: 0.438. Train Loss: 106.167\n",
      "Step. time since epoch: 2.148. Train acc: 0.469. Train Loss: 79.164\n",
      "Step. time since epoch: 2.214. Train acc: 0.531. Train Loss: 39.481\n",
      "Step. time since epoch: 2.286. Train acc: 0.438. Train Loss: 203.793\n",
      "Step. time since epoch: 2.342. Train acc: 0.500. Train Loss: 43.440\n",
      "Step. time since epoch: 2.403. Train acc: 0.562. Train Loss: 68.767\n",
      "Step. time since epoch: 2.443. Train acc: 0.450. Train Loss: 36.256\n",
      "epoch 2, loss 6.3594, train acc 0.484, test acc 0.542, time 5.2 sec\n",
      "Step. time since epoch: 1.912. Train acc: 0.500. Train Loss: 37.130\n",
      "Step. time since epoch: 2.043. Train acc: 0.500. Train Loss: 33.079\n",
      "Step. time since epoch: 2.143. Train acc: 0.531. Train Loss: 26.557\n",
      "Step. time since epoch: 2.215. Train acc: 0.625. Train Loss: 21.591\n",
      "Step. time since epoch: 2.278. Train acc: 0.531. Train Loss: 21.995\n",
      "Step. time since epoch: 2.335. Train acc: 0.500. Train Loss: 22.761\n",
      "Step. time since epoch: 2.393. Train acc: 0.656. Train Loss: 21.751\n",
      "Step. time since epoch: 2.433. Train acc: 0.150. Train Loss: 23.398\n",
      "epoch 3, loss 0.8535, train acc 0.516, test acc 0.458, time 5.2 sec\n",
      "Step. time since epoch: 1.924. Train acc: 0.500. Train Loss: 22.519\n",
      "Step. time since epoch: 2.076. Train acc: 0.562. Train Loss: 23.952\n",
      "Step. time since epoch: 2.163. Train acc: 0.375. Train Loss: 28.198\n",
      "Step. time since epoch: 2.256. Train acc: 0.375. Train Loss: 22.893\n",
      "Step. time since epoch: 2.321. Train acc: 0.406. Train Loss: 24.989\n",
      "Step. time since epoch: 2.385. Train acc: 0.531. Train Loss: 22.279\n",
      "Step. time since epoch: 2.447. Train acc: 0.500. Train Loss: 22.111\n",
      "Step. time since epoch: 2.490. Train acc: 0.350. Train Loss: 14.233\n",
      "epoch 4, loss 0.7425, train acc 0.455, test acc 0.458, time 5.1 sec\n",
      "Step. time since epoch: 1.888. Train acc: 0.438. Train Loss: 22.460\n",
      "Step. time since epoch: 2.015. Train acc: 0.625. Train Loss: 21.969\n",
      "Step. time since epoch: 2.085. Train acc: 0.656. Train Loss: 21.921\n",
      "Step. time since epoch: 2.205. Train acc: 0.344. Train Loss: 23.216\n",
      "Step. time since epoch: 2.264. Train acc: 0.531. Train Loss: 22.080\n",
      "Step. time since epoch: 2.321. Train acc: 0.562. Train Loss: 22.011\n",
      "Step. time since epoch: 2.377. Train acc: 0.406. Train Loss: 22.667\n",
      "Step. time since epoch: 2.417. Train acc: 0.500. Train Loss: 13.733\n",
      "epoch 5, loss 0.6970, train acc 0.508, test acc 0.458, time 5.2 sec\n",
      "Step. time since epoch: 1.898. Train acc: 0.438. Train Loss: 22.618\n",
      "Step. time since epoch: 2.004. Train acc: 0.531. Train Loss: 22.059\n",
      "Step. time since epoch: 2.071. Train acc: 0.500. Train Loss: 22.163\n",
      "Step. time since epoch: 2.187. Train acc: 0.438. Train Loss: 22.291\n",
      "Step. time since epoch: 2.250. Train acc: 0.594. Train Loss: 22.195\n",
      "Step. time since epoch: 2.310. Train acc: 0.531. Train Loss: 22.019\n",
      "Step. time since epoch: 2.366. Train acc: 0.375. Train Loss: 23.131\n",
      "Step. time since epoch: 2.408. Train acc: 0.550. Train Loss: 13.615\n",
      "epoch 6, loss 0.6971, train acc 0.492, test acc 0.621, time 5.0 sec\n",
      "Step. time since epoch: 1.988. Train acc: 0.750. Train Loss: 21.904\n",
      "Step. time since epoch: 2.055. Train acc: 0.625. Train Loss: 21.367\n",
      "Step. time since epoch: 2.237. Train acc: 0.594. Train Loss: 21.572\n",
      "Step. time since epoch: 2.309. Train acc: 0.438. Train Loss: 23.808\n",
      "Step. time since epoch: 2.367. Train acc: 0.500. Train Loss: 22.708\n",
      "Step. time since epoch: 2.424. Train acc: 0.438. Train Loss: 23.255\n",
      "Step. time since epoch: 2.487. Train acc: 0.719. Train Loss: 21.530\n",
      "Step. time since epoch: 2.528. Train acc: 0.700. Train Loss: 13.514\n",
      "epoch 7, loss 0.6953, train acc 0.590, test acc 0.542, time 5.2 sec\n",
      "Step. time since epoch: 1.934. Train acc: 0.344. Train Loss: 24.534\n",
      "Step. time since epoch: 2.002. Train acc: 0.500. Train Loss: 22.703\n",
      "Step. time since epoch: 2.107. Train acc: 0.438. Train Loss: 23.186\n",
      "Step. time since epoch: 2.176. Train acc: 0.812. Train Loss: 21.041\n",
      "Step. time since epoch: 2.233. Train acc: 0.562. Train Loss: 22.118\n",
      "Step. time since epoch: 2.294. Train acc: 0.531. Train Loss: 22.389\n",
      "Step. time since epoch: 2.351. Train acc: 0.625. Train Loss: 21.543\n",
      "Step. time since epoch: 2.392. Train acc: 0.700. Train Loss: 13.557\n",
      "epoch 8, loss 0.7011, train acc 0.557, test acc 0.588, time 5.5 sec\n",
      "Step. time since epoch: 1.928. Train acc: 0.500. Train Loss: 22.423\n",
      "Step. time since epoch: 2.013. Train acc: 0.500. Train Loss: 22.389\n",
      "Step. time since epoch: 2.081. Train acc: 0.625. Train Loss: 21.396\n",
      "Step. time since epoch: 2.177. Train acc: 0.562. Train Loss: 21.480\n",
      "Step. time since epoch: 2.238. Train acc: 0.531. Train Loss: 21.958\n",
      "Step. time since epoch: 2.295. Train acc: 0.656. Train Loss: 21.094\n",
      "Step. time since epoch: 2.351. Train acc: 0.656. Train Loss: 21.072\n",
      "Step. time since epoch: 2.391. Train acc: 0.600. Train Loss: 13.610\n",
      "epoch 9, loss 0.6780, train acc 0.578, test acc 0.562, time 5.1 sec\n",
      "Step. time since epoch: 1.843. Train acc: 0.594. Train Loss: 21.722\n",
      "Step. time since epoch: 1.987. Train acc: 0.656. Train Loss: 20.947\n",
      "Step. time since epoch: 2.127. Train acc: 0.594. Train Loss: 20.430\n",
      "Step. time since epoch: 2.194. Train acc: 0.594. Train Loss: 20.576\n",
      "Step. time since epoch: 2.253. Train acc: 0.562. Train Loss: 22.645\n",
      "Step. time since epoch: 2.311. Train acc: 0.688. Train Loss: 20.738\n",
      "Step. time since epoch: 2.372. Train acc: 0.656. Train Loss: 21.430\n",
      "Step. time since epoch: 2.413. Train acc: 0.600. Train Loss: 12.794\n",
      "epoch 10, loss 0.6610, train acc 0.619, test acc 0.601, time 5.1 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.001, 10\n",
    "trainer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "train(model, dataloaders_dict['train'], dataloaders_dict['val'], trainer, num_epochs, dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release CUDA\n",
    "model.eval()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net, dev):\n",
    "    acc_sum, n = torch.Tensor([0]).to(dev), 0\n",
    "    net.eval()\n",
    "    for X, y in data_iter:\n",
    "        X, y = X.to(dev), y.to(dev)\n",
    "        acc_sum += (net(X).argmax(axis=1) == y).sum()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum.item() / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_iter, test_iter, trainer, num_epochs, dev):\n",
    "    loss = nn.CrossEntropyLoss(reduction='sum')\n",
    "    net.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            trainer.zero_grad()\n",
    "            X, y = X.to(dev), y.to(dev)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "            print(\"Step. time since epoch: {:.3f}. Train acc: {:.3f}. Train Loss: {:.3f}\".format(time.time() -  start,\n",
    "                (y_hat.argmax(axis=1) == y).sum().item() / y.shape[0], l.item()))\n",
    "        test_acc = evaluate_accuracy(test_iter, net, dev)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\n",
    "              'time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc,\n",
    "                 time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 2.194. Train acc: 0.000. Train Loss: 222.072\n",
      "Step. time since epoch: 2.409. Train acc: 0.406. Train Loss: 2303.064\n",
      "Step. time since epoch: 2.619. Train acc: 0.625. Train Loss: 165.540\n",
      "Step. time since epoch: 2.831. Train acc: 0.344. Train Loss: 2576.320\n",
      "Step. time since epoch: 3.040. Train acc: 0.500. Train Loss: 195.303\n",
      "Step. time since epoch: 3.249. Train acc: 0.500. Train Loss: 207.591\n",
      "Step. time since epoch: 3.460. Train acc: 0.469. Train Loss: 194.175\n",
      "Step. time since epoch: 3.621. Train acc: 0.500. Train Loss: 78.920\n",
      "epoch 1, loss 24.3565, train acc 0.414, test acc 0.542, time 6.6 sec\n",
      "Step. time since epoch: 2.351. Train acc: 0.531. Train Loss: 356.930\n",
      "Step. time since epoch: 2.569. Train acc: 0.375. Train Loss: 125.205\n",
      "Step. time since epoch: 2.781. Train acc: 0.531. Train Loss: 152.926\n",
      "Step. time since epoch: 2.992. Train acc: 0.469. Train Loss: 157.170\n",
      "Step. time since epoch: 3.204. Train acc: 0.531. Train Loss: 133.441\n",
      "Step. time since epoch: 3.412. Train acc: 0.469. Train Loss: 104.949\n",
      "Step. time since epoch: 3.624. Train acc: 0.500. Train Loss: 92.390\n",
      "Step. time since epoch: 3.783. Train acc: 0.600. Train Loss: 50.403\n",
      "epoch 2, loss 4.8091, train acc 0.496, test acc 0.542, time 7.3 sec\n",
      "Step. time since epoch: 2.338. Train acc: 0.438. Train Loss: 113.751\n",
      "Step. time since epoch: 2.554. Train acc: 0.688. Train Loss: 56.103\n",
      "Step. time since epoch: 2.762. Train acc: 0.281. Train Loss: 108.333\n",
      "Step. time since epoch: 2.974. Train acc: 0.562. Train Loss: 61.646\n",
      "Step. time since epoch: 3.181. Train acc: 0.469. Train Loss: 74.004\n",
      "Step. time since epoch: 3.390. Train acc: 0.375. Train Loss: 75.101\n",
      "Step. time since epoch: 3.601. Train acc: 0.625. Train Loss: 43.843\n",
      "Step. time since epoch: 3.762. Train acc: 0.550. Train Loss: 28.185\n",
      "epoch 3, loss 2.2990, train acc 0.496, test acc 0.542, time 6.7 sec\n",
      "Step. time since epoch: 2.241. Train acc: 0.500. Train Loss: 46.923\n",
      "Step. time since epoch: 2.458. Train acc: 0.500. Train Loss: 40.681\n",
      "Step. time since epoch: 2.668. Train acc: 0.625. Train Loss: 25.297\n",
      "Step. time since epoch: 2.880. Train acc: 0.562. Train Loss: 23.056\n",
      "Step. time since epoch: 3.088. Train acc: 0.500. Train Loss: 23.634\n",
      "Step. time since epoch: 3.297. Train acc: 0.594. Train Loss: 24.705\n",
      "Step. time since epoch: 3.506. Train acc: 0.625. Train Loss: 26.003\n",
      "Step. time since epoch: 3.667. Train acc: 0.500. Train Loss: 21.129\n",
      "epoch 4, loss 0.9485, train acc 0.553, test acc 0.458, time 7.0 sec\n",
      "Step. time since epoch: 2.241. Train acc: 0.469. Train Loss: 32.893\n",
      "Step. time since epoch: 2.456. Train acc: 0.531. Train Loss: 24.813\n",
      "Step. time since epoch: 2.667. Train acc: 0.562. Train Loss: 21.945\n",
      "Step. time since epoch: 2.875. Train acc: 0.500. Train Loss: 22.935\n",
      "Step. time since epoch: 3.086. Train acc: 0.531. Train Loss: 24.245\n",
      "Step. time since epoch: 3.295. Train acc: 0.531. Train Loss: 25.323\n",
      "Step. time since epoch: 3.504. Train acc: 0.531. Train Loss: 24.958\n",
      "Step. time since epoch: 3.664. Train acc: 0.400. Train Loss: 16.871\n",
      "epoch 5, loss 0.7950, train acc 0.512, test acc 0.542, time 6.5 sec\n",
      "Step. time since epoch: 2.428. Train acc: 0.406. Train Loss: 24.320\n",
      "Step. time since epoch: 2.648. Train acc: 0.469. Train Loss: 22.200\n",
      "Step. time since epoch: 2.857. Train acc: 0.531. Train Loss: 22.408\n",
      "Step. time since epoch: 3.067. Train acc: 0.469. Train Loss: 24.807\n",
      "Step. time since epoch: 3.275. Train acc: 0.469. Train Loss: 25.463\n",
      "Step. time since epoch: 3.487. Train acc: 0.344. Train Loss: 27.707\n",
      "Step. time since epoch: 3.697. Train acc: 0.531. Train Loss: 22.448\n",
      "Step. time since epoch: 3.857. Train acc: 0.600. Train Loss: 13.681\n",
      "epoch 6, loss 0.7501, train acc 0.471, test acc 0.542, time 6.7 sec\n",
      "Step. time since epoch: 2.192. Train acc: 0.469. Train Loss: 22.364\n",
      "Step. time since epoch: 2.403. Train acc: 0.500. Train Loss: 22.498\n",
      "Step. time since epoch: 2.616. Train acc: 0.531. Train Loss: 22.384\n",
      "Step. time since epoch: 2.826. Train acc: 0.656. Train Loss: 20.788\n",
      "Step. time since epoch: 3.036. Train acc: 0.469. Train Loss: 23.713\n",
      "Step. time since epoch: 3.244. Train acc: 0.531. Train Loss: 22.677\n",
      "Step. time since epoch: 3.453. Train acc: 0.438. Train Loss: 23.855\n",
      "Step. time since epoch: 3.613. Train acc: 0.300. Train Loss: 15.387\n",
      "epoch 7, loss 0.7117, train acc 0.496, test acc 0.542, time 6.5 sec\n",
      "Step. time since epoch: 2.243. Train acc: 0.656. Train Loss: 21.754\n",
      "Step. time since epoch: 2.464. Train acc: 0.469. Train Loss: 22.363\n",
      "Step. time since epoch: 2.680. Train acc: 0.531. Train Loss: 22.302\n",
      "Step. time since epoch: 2.891. Train acc: 0.688. Train Loss: 21.379\n",
      "Step. time since epoch: 3.099. Train acc: 0.500. Train Loss: 22.813\n",
      "Step. time since epoch: 3.310. Train acc: 0.562. Train Loss: 22.219\n",
      "Step. time since epoch: 3.522. Train acc: 0.375. Train Loss: 25.388\n",
      "Step. time since epoch: 3.681. Train acc: 0.500. Train Loss: 14.393\n",
      "epoch 8, loss 0.7074, train acc 0.537, test acc 0.458, time 6.5 sec\n",
      "Step. time since epoch: 2.171. Train acc: 0.625. Train Loss: 21.366\n",
      "Step. time since epoch: 2.426. Train acc: 0.344. Train Loss: 23.804\n",
      "Step. time since epoch: 2.638. Train acc: 0.406. Train Loss: 22.499\n",
      "Step. time since epoch: 2.848. Train acc: 0.469. Train Loss: 22.408\n",
      "Step. time since epoch: 3.056. Train acc: 0.438. Train Loss: 23.120\n",
      "Step. time since epoch: 3.265. Train acc: 0.438. Train Loss: 23.485\n",
      "Step. time since epoch: 3.475. Train acc: 0.438. Train Loss: 23.479\n",
      "Step. time since epoch: 3.636. Train acc: 0.600. Train Loss: 13.501\n",
      "epoch 9, loss 0.7117, train acc 0.463, test acc 0.542, time 6.5 sec\n",
      "Step. time since epoch: 2.167. Train acc: 0.562. Train Loss: 21.950\n",
      "Step. time since epoch: 2.385. Train acc: 0.438. Train Loss: 22.712\n",
      "Step. time since epoch: 2.595. Train acc: 0.500. Train Loss: 22.233\n",
      "Step. time since epoch: 2.804. Train acc: 0.469. Train Loss: 22.216\n",
      "Step. time since epoch: 3.020. Train acc: 0.625. Train Loss: 21.889\n",
      "Step. time since epoch: 3.247. Train acc: 0.469. Train Loss: 22.581\n",
      "Step. time since epoch: 3.464. Train acc: 0.594. Train Loss: 21.684\n",
      "Step. time since epoch: 3.634. Train acc: 0.300. Train Loss: 15.564\n",
      "epoch 10, loss 0.7001, train acc 0.504, test acc 0.458, time 6.5 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.001, 10\n",
    "trainer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "train(model, dataloaders_dict['train'], dataloaders_dict['val'], trainer, num_epochs, dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Обучите на нем модели ResNet 18 и VGG 16 с использованием FineTuning (5-10 эпох)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet 18 pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T17:23:47.319979Z",
     "start_time": "2019-11-18T17:23:47.316747Z"
    }
   },
   "outputs": [],
   "source": [
    "## Убираем требование градиента:\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T17:24:04.770976Z",
     "start_time": "2019-11-18T17:24:04.766810Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T17:24:12.305790Z",
     "start_time": "2019-11-18T17:24:12.302517Z"
    }
   },
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(in_features=512, out_features=2).to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T17:24:42.228326Z",
     "start_time": "2019-11-18T17:24:42.222643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "print(\"Params to learn:\")\n",
    "params_to_update = []\n",
    "for name,param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net, dev):\n",
    "    acc_sum, n = torch.Tensor([0]).to(dev), 0\n",
    "    net.eval()\n",
    "    for X, y in data_iter:\n",
    "        X, y = X.to(dev), y.to(dev)\n",
    "        acc_sum += (net(X).argmax(axis=1) == y).sum()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum.item() / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_iter, test_iter, trainer, num_epochs, dev):\n",
    "    loss = nn.CrossEntropyLoss(reduction='sum')\n",
    "    net.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            trainer.zero_grad()\n",
    "            X, y = X.to(dev), y.to(dev)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "            print(\"Step. time since epoch: {:.3f}. Train acc: {:.3f}. Train Loss: {:.3f}\".format(time.time() -  start,\n",
    "                (y_hat.argmax(axis=1) == y).sum().item() / y.shape[0], l.item()))\n",
    "        test_acc = evaluate_accuracy(test_iter, net, dev)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\n",
    "              'time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc,\n",
    "                 time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 2.023. Train acc: 0.438. Train Loss: 25.014\n",
      "Step. time since epoch: 2.219. Train acc: 0.500. Train Loss: 24.005\n",
      "Step. time since epoch: 2.275. Train acc: 0.594. Train Loss: 23.093\n",
      "Step. time since epoch: 2.394. Train acc: 0.625. Train Loss: 19.624\n",
      "Step. time since epoch: 2.432. Train acc: 0.562. Train Loss: 21.490\n",
      "Step. time since epoch: 2.485. Train acc: 0.688. Train Loss: 17.720\n",
      "Step. time since epoch: 2.515. Train acc: 0.750. Train Loss: 17.392\n",
      "Step. time since epoch: 2.559. Train acc: 0.600. Train Loss: 12.999\n",
      "epoch 1, loss 0.6612, train acc 0.594, test acc 0.784, time 5.5 sec\n",
      "Step. time since epoch: 2.047. Train acc: 0.719. Train Loss: 15.903\n",
      "Step. time since epoch: 2.136. Train acc: 0.781. Train Loss: 16.223\n",
      "Step. time since epoch: 2.282. Train acc: 0.812. Train Loss: 14.634\n",
      "Step. time since epoch: 2.782. Train acc: 0.906. Train Loss: 12.224\n",
      "Step. time since epoch: 2.812. Train acc: 0.844. Train Loss: 12.527\n",
      "Step. time since epoch: 2.840. Train acc: 0.812. Train Loss: 12.392\n",
      "Step. time since epoch: 2.869. Train acc: 0.812. Train Loss: 14.091\n",
      "Step. time since epoch: 2.889. Train acc: 0.850. Train Loss: 9.014\n",
      "epoch 2, loss 0.4386, train acc 0.816, test acc 0.908, time 5.7 sec\n",
      "Step. time since epoch: 2.052. Train acc: 0.906. Train Loss: 9.796\n",
      "Step. time since epoch: 2.102. Train acc: 0.844. Train Loss: 9.264\n",
      "Step. time since epoch: 2.267. Train acc: 0.719. Train Loss: 14.228\n",
      "Step. time since epoch: 2.390. Train acc: 0.844. Train Loss: 12.157\n",
      "Step. time since epoch: 2.419. Train acc: 0.938. Train Loss: 9.065\n",
      "Step. time since epoch: 2.449. Train acc: 1.000. Train Loss: 6.109\n",
      "Step. time since epoch: 2.499. Train acc: 0.906. Train Loss: 10.012\n",
      "Step. time since epoch: 2.521. Train acc: 0.900. Train Loss: 6.085\n",
      "epoch 3, loss 0.3144, train acc 0.881, test acc 0.928, time 5.4 sec\n",
      "Step. time since epoch: 1.944. Train acc: 0.906. Train Loss: 7.205\n",
      "Step. time since epoch: 2.079. Train acc: 0.906. Train Loss: 8.407\n",
      "Step. time since epoch: 2.244. Train acc: 0.906. Train Loss: 8.312\n",
      "Step. time since epoch: 2.380. Train acc: 0.875. Train Loss: 7.972\n",
      "Step. time since epoch: 2.415. Train acc: 0.875. Train Loss: 9.548\n",
      "Step. time since epoch: 2.446. Train acc: 0.969. Train Loss: 6.174\n",
      "Step. time since epoch: 2.484. Train acc: 0.969. Train Loss: 7.467\n",
      "Step. time since epoch: 2.516. Train acc: 1.000. Train Loss: 3.377\n",
      "epoch 4, loss 0.2396, train acc 0.922, test acc 0.954, time 5.3 sec\n",
      "Step. time since epoch: 1.932. Train acc: 0.938. Train Loss: 7.742\n",
      "Step. time since epoch: 2.052. Train acc: 0.906. Train Loss: 8.970\n",
      "Step. time since epoch: 2.132. Train acc: 0.938. Train Loss: 6.185\n",
      "Step. time since epoch: 2.268. Train acc: 0.969. Train Loss: 6.131\n",
      "Step. time since epoch: 2.298. Train acc: 0.844. Train Loss: 9.639\n",
      "Step. time since epoch: 2.329. Train acc: 0.969. Train Loss: 6.848\n",
      "Step. time since epoch: 2.369. Train acc: 0.938. Train Loss: 7.197\n",
      "Step. time since epoch: 2.392. Train acc: 1.000. Train Loss: 2.948\n",
      "epoch 5, loss 0.2281, train acc 0.934, test acc 0.954, time 5.3 sec\n",
      "Step. time since epoch: 2.102. Train acc: 0.969. Train Loss: 5.235\n",
      "Step. time since epoch: 2.288. Train acc: 0.969. Train Loss: 5.486\n",
      "Step. time since epoch: 2.334. Train acc: 1.000. Train Loss: 4.680\n",
      "Step. time since epoch: 2.545. Train acc: 0.969. Train Loss: 3.984\n",
      "Step. time since epoch: 2.574. Train acc: 0.938. Train Loss: 6.892\n",
      "Step. time since epoch: 2.603. Train acc: 0.938. Train Loss: 5.783\n",
      "Step. time since epoch: 2.634. Train acc: 1.000. Train Loss: 4.698\n",
      "Step. time since epoch: 2.655. Train acc: 0.900. Train Loss: 5.827\n",
      "epoch 6, loss 0.1745, train acc 0.963, test acc 0.941, time 5.6 sec\n",
      "Step. time since epoch: 2.003. Train acc: 0.969. Train Loss: 5.448\n",
      "Step. time since epoch: 2.135. Train acc: 0.906. Train Loss: 7.363\n",
      "Step. time since epoch: 2.210. Train acc: 0.938. Train Loss: 4.784\n",
      "Step. time since epoch: 2.354. Train acc: 0.938. Train Loss: 6.457\n",
      "Step. time since epoch: 2.383. Train acc: 1.000. Train Loss: 4.823\n",
      "Step. time since epoch: 2.413. Train acc: 0.969. Train Loss: 5.245\n",
      "Step. time since epoch: 2.484. Train acc: 0.969. Train Loss: 5.352\n",
      "Step. time since epoch: 2.504. Train acc: 1.000. Train Loss: 2.626\n",
      "epoch 7, loss 0.1725, train acc 0.959, test acc 0.954, time 5.4 sec\n",
      "Step. time since epoch: 1.995. Train acc: 0.969. Train Loss: 6.727\n",
      "Step. time since epoch: 2.027. Train acc: 0.938. Train Loss: 6.022\n",
      "Step. time since epoch: 2.222. Train acc: 0.938. Train Loss: 5.015\n",
      "Step. time since epoch: 2.317. Train acc: 0.938. Train Loss: 6.234\n",
      "Step. time since epoch: 2.347. Train acc: 1.000. Train Loss: 2.449\n",
      "Step. time since epoch: 2.379. Train acc: 0.969. Train Loss: 5.388\n",
      "Step. time since epoch: 2.438. Train acc: 0.938. Train Loss: 4.726\n",
      "Step. time since epoch: 2.460. Train acc: 1.000. Train Loss: 2.593\n",
      "epoch 8, loss 0.1605, train acc 0.959, test acc 0.954, time 5.3 sec\n",
      "Step. time since epoch: 1.937. Train acc: 0.906. Train Loss: 7.430\n",
      "Step. time since epoch: 2.022. Train acc: 0.969. Train Loss: 5.647\n",
      "Step. time since epoch: 2.101. Train acc: 0.875. Train Loss: 7.060\n",
      "Step. time since epoch: 2.238. Train acc: 0.938. Train Loss: 6.362\n",
      "Step. time since epoch: 2.273. Train acc: 0.906. Train Loss: 7.334\n",
      "Step. time since epoch: 2.304. Train acc: 0.969. Train Loss: 2.583\n",
      "Step. time since epoch: 2.334. Train acc: 1.000. Train Loss: 3.621\n",
      "Step. time since epoch: 2.354. Train acc: 0.950. Train Loss: 3.324\n",
      "epoch 9, loss 0.1777, train acc 0.939, test acc 0.948, time 5.2 sec\n",
      "Step. time since epoch: 2.118. Train acc: 1.000. Train Loss: 2.925\n",
      "Step. time since epoch: 2.153. Train acc: 0.969. Train Loss: 3.362\n",
      "Step. time since epoch: 2.268. Train acc: 0.906. Train Loss: 4.603\n",
      "Step. time since epoch: 2.436. Train acc: 0.969. Train Loss: 4.211\n",
      "Step. time since epoch: 2.471. Train acc: 0.969. Train Loss: 5.581\n",
      "Step. time since epoch: 2.499. Train acc: 0.969. Train Loss: 4.014\n",
      "Step. time since epoch: 2.528. Train acc: 0.969. Train Loss: 5.672\n",
      "Step. time since epoch: 2.549. Train acc: 0.950. Train Loss: 2.987\n",
      "epoch 10, loss 0.1367, train acc 0.963, test acc 0.967, time 5.3 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.001, 10\n",
    "trainer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "train(model, dataloaders_dict['train'], dataloaders_dict['val'], trainer, num_epochs, dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release CUDA\n",
    "model.eval()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG 16 pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T17:23:47.319979Z",
     "start_time": "2019-11-18T17:23:47.316747Z"
    }
   },
   "outputs": [],
   "source": [
    "## Убираем требование градиента:\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T17:24:04.770976Z",
     "start_time": "2019-11-18T17:24:04.766810Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (4): ReLU(inplace=True)\n",
       "  (5): Dropout(p=0.5, inplace=False)\n",
       "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T17:24:12.305790Z",
     "start_time": "2019-11-18T17:24:12.302517Z"
    }
   },
   "outputs": [],
   "source": [
    "model.classifier[6] = nn.Linear(in_features=4096, out_features=2).to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T17:24:42.228326Z",
     "start_time": "2019-11-18T17:24:42.222643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t classifier.6.weight\n",
      "\t classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "print(\"Params to learn:\")\n",
    "params_to_update = []\n",
    "for name,param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net, dev):\n",
    "    acc_sum, n = torch.Tensor([0]).to(dev), 0\n",
    "    net.eval()\n",
    "    for X, y in data_iter:\n",
    "        X, y = X.to(dev), y.to(dev)\n",
    "        acc_sum += (net(X).argmax(axis=1) == y).sum()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum.item() / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_iter, test_iter, trainer, num_epochs, dev):\n",
    "    loss = nn.CrossEntropyLoss(reduction='sum')\n",
    "    net.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            trainer.zero_grad()\n",
    "            X, y = X.to(dev), y.to(dev)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "            print(\"Step. time since epoch: {:.3f}. Train acc: {:.3f}. Train Loss: {:.3f}\".format(time.time() -  start,\n",
    "                (y_hat.argmax(axis=1) == y).sum().item() / y.shape[0], l.item()))\n",
    "        test_acc = evaluate_accuracy(test_iter, net, dev)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\n",
    "              'time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc,\n",
    "                 time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 2.046. Train acc: 0.406. Train Loss: 30.381\n",
      "Step. time since epoch: 2.129. Train acc: 0.750. Train Loss: 17.031\n",
      "Step. time since epoch: 2.217. Train acc: 0.781. Train Loss: 16.184\n",
      "Step. time since epoch: 2.368. Train acc: 0.844. Train Loss: 11.024\n",
      "Step. time since epoch: 2.439. Train acc: 0.875. Train Loss: 10.705\n",
      "Step. time since epoch: 2.511. Train acc: 0.938. Train Loss: 7.620\n",
      "Step. time since epoch: 2.584. Train acc: 0.938. Train Loss: 7.114\n",
      "Step. time since epoch: 2.639. Train acc: 0.850. Train Loss: 5.080\n",
      "epoch 1, loss 0.4309, train acc 0.795, test acc 0.948, time 5.4 sec\n",
      "Step. time since epoch: 1.903. Train acc: 0.969. Train Loss: 3.970\n",
      "Step. time since epoch: 2.017. Train acc: 0.938. Train Loss: 4.808\n",
      "Step. time since epoch: 2.095. Train acc: 0.969. Train Loss: 5.213\n",
      "Step. time since epoch: 2.176. Train acc: 0.938. Train Loss: 8.003\n",
      "Step. time since epoch: 2.248. Train acc: 0.938. Train Loss: 2.854\n",
      "Step. time since epoch: 2.316. Train acc: 0.906. Train Loss: 4.531\n",
      "Step. time since epoch: 2.385. Train acc: 0.938. Train Loss: 4.194\n",
      "Step. time since epoch: 2.438. Train acc: 1.000. Train Loss: 2.408\n",
      "epoch 2, loss 0.1475, train acc 0.947, test acc 0.961, time 5.2 sec\n",
      "Step. time since epoch: 1.900. Train acc: 1.000. Train Loss: 1.797\n",
      "Step. time since epoch: 2.036. Train acc: 0.875. Train Loss: 5.409\n",
      "Step. time since epoch: 2.119. Train acc: 1.000. Train Loss: 1.180\n",
      "Step. time since epoch: 2.215. Train acc: 0.938. Train Loss: 6.183\n",
      "Step. time since epoch: 2.285. Train acc: 1.000. Train Loss: 2.084\n",
      "Step. time since epoch: 2.356. Train acc: 1.000. Train Loss: 1.337\n",
      "Step. time since epoch: 2.424. Train acc: 1.000. Train Loss: 2.540\n",
      "Step. time since epoch: 2.478. Train acc: 0.950. Train Loss: 2.658\n",
      "epoch 3, loss 0.0950, train acc 0.971, test acc 0.954, time 5.2 sec\n",
      "Step. time since epoch: 1.908. Train acc: 0.969. Train Loss: 4.709\n",
      "Step. time since epoch: 2.019. Train acc: 0.969. Train Loss: 2.602\n",
      "Step. time since epoch: 2.129. Train acc: 0.969. Train Loss: 2.195\n",
      "Step. time since epoch: 2.246. Train acc: 0.969. Train Loss: 2.629\n",
      "Step. time since epoch: 2.318. Train acc: 1.000. Train Loss: 1.463\n",
      "Step. time since epoch: 2.389. Train acc: 0.938. Train Loss: 5.232\n",
      "Step. time since epoch: 2.457. Train acc: 0.906. Train Loss: 3.538\n",
      "Step. time since epoch: 2.511. Train acc: 0.950. Train Loss: 1.410\n",
      "epoch 4, loss 0.0975, train acc 0.959, test acc 0.954, time 5.3 sec\n",
      "Step. time since epoch: 1.931. Train acc: 0.969. Train Loss: 3.483\n",
      "Step. time since epoch: 2.064. Train acc: 0.969. Train Loss: 2.082\n",
      "Step. time since epoch: 2.143. Train acc: 1.000. Train Loss: 1.482\n",
      "Step. time since epoch: 2.220. Train acc: 0.969. Train Loss: 3.090\n",
      "Step. time since epoch: 2.290. Train acc: 0.906. Train Loss: 4.904\n",
      "Step. time since epoch: 2.359. Train acc: 0.969. Train Loss: 3.078\n",
      "Step. time since epoch: 2.428. Train acc: 0.906. Train Loss: 3.683\n",
      "Step. time since epoch: 2.482. Train acc: 0.950. Train Loss: 2.716\n",
      "epoch 5, loss 0.1005, train acc 0.955, test acc 0.961, time 5.3 sec\n",
      "Step. time since epoch: 1.907. Train acc: 1.000. Train Loss: 1.430\n",
      "Step. time since epoch: 2.100. Train acc: 1.000. Train Loss: 2.055\n",
      "Step. time since epoch: 2.188. Train acc: 0.938. Train Loss: 3.894\n",
      "Step. time since epoch: 2.264. Train acc: 0.938. Train Loss: 3.766\n",
      "Step. time since epoch: 2.333. Train acc: 1.000. Train Loss: 1.936\n",
      "Step. time since epoch: 2.401. Train acc: 1.000. Train Loss: 0.418\n",
      "Step. time since epoch: 2.471. Train acc: 0.906. Train Loss: 5.416\n",
      "Step. time since epoch: 2.525. Train acc: 1.000. Train Loss: 1.016\n",
      "epoch 6, loss 0.0817, train acc 0.971, test acc 0.954, time 5.2 sec\n",
      "Step. time since epoch: 1.863. Train acc: 0.938. Train Loss: 4.188\n",
      "Step. time since epoch: 1.973. Train acc: 0.969. Train Loss: 2.589\n",
      "Step. time since epoch: 2.089. Train acc: 1.000. Train Loss: 2.418\n",
      "Step. time since epoch: 2.204. Train acc: 1.000. Train Loss: 1.520\n",
      "Step. time since epoch: 2.275. Train acc: 0.844. Train Loss: 8.148\n",
      "Step. time since epoch: 2.346. Train acc: 0.875. Train Loss: 6.139\n",
      "Step. time since epoch: 2.414. Train acc: 0.969. Train Loss: 2.516\n",
      "Step. time since epoch: 2.468. Train acc: 1.000. Train Loss: 0.526\n",
      "epoch 7, loss 0.1149, train acc 0.947, test acc 0.961, time 5.2 sec\n",
      "Step. time since epoch: 1.887. Train acc: 0.875. Train Loss: 5.072\n",
      "Step. time since epoch: 2.012. Train acc: 0.938. Train Loss: 3.142\n",
      "Step. time since epoch: 2.118. Train acc: 0.969. Train Loss: 2.269\n",
      "Step. time since epoch: 2.205. Train acc: 1.000. Train Loss: 1.139\n",
      "Step. time since epoch: 2.278. Train acc: 0.938. Train Loss: 4.594\n",
      "Step. time since epoch: 2.347. Train acc: 0.938. Train Loss: 4.511\n",
      "Step. time since epoch: 2.416. Train acc: 1.000. Train Loss: 1.551\n",
      "Step. time since epoch: 2.469. Train acc: 0.950. Train Loss: 2.474\n",
      "epoch 8, loss 0.1014, train acc 0.951, test acc 0.961, time 5.2 sec\n",
      "Step. time since epoch: 1.881. Train acc: 1.000. Train Loss: 1.428\n",
      "Step. time since epoch: 1.965. Train acc: 1.000. Train Loss: 2.071\n",
      "Step. time since epoch: 2.096. Train acc: 0.969. Train Loss: 2.008\n",
      "Step. time since epoch: 2.197. Train acc: 1.000. Train Loss: 2.819\n",
      "Step. time since epoch: 2.268. Train acc: 1.000. Train Loss: 1.015\n",
      "Step. time since epoch: 2.338. Train acc: 1.000. Train Loss: 1.412\n",
      "Step. time since epoch: 2.407. Train acc: 0.938. Train Loss: 2.920\n",
      "Step. time since epoch: 2.462. Train acc: 1.000. Train Loss: 0.838\n",
      "epoch 9, loss 0.0595, train acc 0.988, test acc 0.961, time 5.1 sec\n",
      "Step. time since epoch: 1.899. Train acc: 0.938. Train Loss: 3.311\n",
      "Step. time since epoch: 2.038. Train acc: 1.000. Train Loss: 0.630\n",
      "Step. time since epoch: 2.132. Train acc: 1.000. Train Loss: 0.634\n",
      "Step. time since epoch: 2.211. Train acc: 0.875. Train Loss: 8.056\n",
      "Step. time since epoch: 2.281. Train acc: 0.969. Train Loss: 1.818\n",
      "Step. time since epoch: 2.351. Train acc: 0.969. Train Loss: 2.772\n",
      "Step. time since epoch: 2.422. Train acc: 1.000. Train Loss: 1.077\n",
      "Step. time since epoch: 2.476. Train acc: 0.950. Train Loss: 2.643\n",
      "epoch 10, loss 0.0858, train acc 0.963, test acc 0.974, time 5.2 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.001, 10\n",
    "trainer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "train(model, dataloaders_dict['train'], dataloaders_dict['val'], trainer, num_epochs, dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Добавьте аугментацию данных к пункту 2  \n",
    "  \n",
    "(Обучите на нем модели ResNet 18 и VGG 16 с использованием FineTuning (5-10 эпох))\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сравните качество всех 3 полученных подходов  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "# Задание со звездочкой  \n",
    "Примените FineTuning ResNet 18 к FashionMnist. Удалось ли увидеть резкое увеличение качества?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
